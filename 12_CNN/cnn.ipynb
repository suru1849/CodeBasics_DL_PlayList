{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras import datasets, layers, models\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load Datasets\n",
    "(X_train, y_train), (X_test, y_test) = datasets.cifar10.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((50000, 32, 32, 3), (10000, 32, 32, 3))"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape, X_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[6],\n",
       "       [9],\n",
       "       [9],\n",
       "       [4],\n",
       "       [1]], dtype=uint8)"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([6, 9, 9, 4, 1], dtype=uint8)"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Converting 2D array into 1D array\n",
    "y_train = y_train.reshape(-1)\n",
    "y_test = y_test.reshape(-1)\n",
    "y_train[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "classes = [\"airplane\", \"automobile\",\"bird\",\"cat\",\"deer\",\"dog\",\"frog\",\"horse\",\"ship\",\"truck\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's plot some images to see what they are\n",
    "def plot_sample(X, y, index):\n",
    "    plt.figure(figsize=(10,2))\n",
    "    plt.imshow(X[index])\n",
    "    plt.xlabel(y[index])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x200 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot_sample(X_train, y_train, 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalize the images to a number from 0 to 1. Image has 3 channels (R,G,B) and each value in the channel can range from 0 to 255. Hence to normalize in 0-->1 range, we need to divide it by 255\n",
    "\n",
    "X_train = X_train/255\n",
    "X_test = X_test/255"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m39s\u001b[0m 25ms/step - accuracy: 0.3017 - loss: 1.9349\n",
      "Epoch 2/5\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m36s\u001b[0m 23ms/step - accuracy: 0.4240 - loss: 1.6407\n",
      "Epoch 3/5\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m37s\u001b[0m 23ms/step - accuracy: 0.4551 - loss: 1.5482\n",
      "Epoch 4/5\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m37s\u001b[0m 24ms/step - accuracy: 0.4800 - loss: 1.4815\n",
      "Epoch 5/5\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m36s\u001b[0m 23ms/step - accuracy: 0.4926 - loss: 1.4325\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.history.History at 0x22e4692af00>"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Build simple artificial neural network for image classification\n",
    "\n",
    "ann = models.Sequential([\n",
    "    layers.Flatten(input_shape=(32,32,3)),\n",
    "    layers.Dense(3000, activation='relu'),\n",
    "    layers.Dense(1000, activation='relu'),\n",
    "    layers.Dense(10, activation='softmax')\n",
    "])\n",
    "\n",
    "ann.compile(optimizer='SGD', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "ann.fit(X_train, y_train, epochs=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "\n",
    "y_pred = ann.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([3, 8, 8, 8, 4], array([3, 8, 8, 0, 6], dtype=uint8))"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred_classes = [np.argmax(element) for element in y_pred]\n",
    "y_pred_classes[:5], y_test[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.4759 - loss: 1.4751\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[1.478654146194458, 0.46970000863075256]"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ann.evaluate(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification Report: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.44      0.68      0.53      1000\n",
      "           1       0.63      0.58      0.61      1000\n",
      "           2       0.51      0.09      0.15      1000\n",
      "           3       0.39      0.26      0.31      1000\n",
      "           4       0.44      0.32      0.37      1000\n",
      "           5       0.51      0.25      0.33      1000\n",
      "           6       0.34      0.83      0.48      1000\n",
      "           7       0.54      0.56      0.55      1000\n",
      "           8       0.55      0.65      0.60      1000\n",
      "           9       0.59      0.47      0.53      1000\n",
      "\n",
      "    accuracy                           0.47     10000\n",
      "   macro avg       0.49      0.47      0.45     10000\n",
      "weighted avg       0.49      0.47      0.45     10000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"Classification Report: \\n\", classification_report(y_test, y_pred_classes))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\keras\\src\\layers\\convolutional\\base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 8ms/step - accuracy: 0.3753 - loss: 1.7154\n",
      "Epoch 2/10\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 8ms/step - accuracy: 0.5902 - loss: 1.1695\n",
      "Epoch 3/10\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 7ms/step - accuracy: 0.6464 - loss: 1.0100\n",
      "Epoch 4/10\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 8ms/step - accuracy: 0.6796 - loss: 0.9215\n",
      "Epoch 5/10\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 7ms/step - accuracy: 0.7032 - loss: 0.8584\n",
      "Epoch 6/10\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 7ms/step - accuracy: 0.7285 - loss: 0.7844\n",
      "Epoch 7/10\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 8ms/step - accuracy: 0.7431 - loss: 0.7399\n",
      "Epoch 8/10\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 7ms/step - accuracy: 0.7599 - loss: 0.6932\n",
      "Epoch 9/10\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 7ms/step - accuracy: 0.7754 - loss: 0.6505\n",
      "Epoch 10/10\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 7ms/step - accuracy: 0.7872 - loss: 0.6162\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.history.History at 0x22e46c6e240>"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Now let us build a convolutional neural network to train our images\n",
    "\n",
    "cnn = models.Sequential([\n",
    "    # cnn\n",
    "    layers.Conv2D(filters=32, kernel_size=(3,3), activation='relu', input_shape=(32,32,3)),\n",
    "    layers.MaxPooling2D((2,2)),\n",
    "    \n",
    "    layers.Conv2D(filters=64, kernel_size=(3, 3),\n",
    "                  activation='relu'),\n",
    "    layers.MaxPooling2D((2, 2)),\n",
    "    \n",
    "    # dense\n",
    "    layers.Flatten(),\n",
    "    layers.Dense(64, activation='relu'),\n",
    "    layers.Dense(10, activation='softmax')\n",
    "    \n",
    "])\n",
    "\n",
    "cnn.compile(optimizer='adam',\n",
    "              loss='sparse_categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "cnn.fit(X_train, y_train, epochs=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.6970 - loss: 0.9336\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.9233019351959229, 0.7003999948501587]"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cnn.evaluate(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step\n"
     ]
    }
   ],
   "source": [
    "y_pred = cnn.predict(X_test)\n",
    "y_pred_classes = [np.argmax(i) for i in y_pred]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.78      0.70      0.74      1000\n",
      "           1       0.81      0.82      0.82      1000\n",
      "           2       0.68      0.52      0.59      1000\n",
      "           3       0.56      0.44      0.49      1000\n",
      "           4       0.64      0.67      0.65      1000\n",
      "           5       0.57      0.65      0.61      1000\n",
      "           6       0.79      0.74      0.77      1000\n",
      "           7       0.65      0.83      0.73      1000\n",
      "           8       0.77      0.84      0.80      1000\n",
      "           9       0.75      0.80      0.77      1000\n",
      "\n",
      "    accuracy                           0.70     10000\n",
      "   macro avg       0.70      0.70      0.70     10000\n",
      "weighted avg       0.70      0.70      0.70     10000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test, y_pred_classes))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
